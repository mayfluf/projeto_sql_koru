# Integra√ß√£o com Google Books API ‚Äî Livraria DevSaber

## Objetivo do Projeto


Este projeto tem como finalidade coletar dados sobre livros relacionados √† programa√ß√£o em Python, utilizando a Google Books API. Os dados extra√≠dos foram organizados em um arquivo CSV, armazenados na nuvem via Google Cloud Storage e posteriormente analisados no BigQuery com consultas em SQL.



O reposit√≥rio cont√©m o c√≥digo, as etapas e as tecnologias utilizadas para construir e analisar os dados da Livraria DevSaber.

---
## Tecnologias Utilizadas

- Google Colab: Ambiente de desenvolvimento utilizado para executar o c√≥digo e interagir com a API.

- Google Books API: API p√∫blica para coleta de dados sobre livros.

- Pandas: Biblioteca Python para manipula√ß√£o e tratamento de dados.

- Google Cloud Storage: Armazenamento em nuvem dos arquivos CSV gerados.

- BigQuery: Plataforma de an√°lise de dados em nuvem para integra√ß√£o e explora√ß√£o dos dados.

- SQL: Linguagem utilizada para consulta e an√°lise dos dados no BigQuery.

---
## Estrutura do Projeto

## 1. üîé Coleta de Dados via API
Utilizamos a API p√∫blica do Google Books para buscar livros relacionados √† programa√ß√£o em Python. A requisi√ß√£o foi feita com os seguintes par√¢metros:

```

url = "https://www.googleapis.com/books/v1/volumes"
params = {
    "q": "python programming",
    "maxResults": 40  # Selecionamos 40 resultados
}
response = requests.get(url, params=params)
response.raise_for_status()
data = response.json()

```
A resposta foi tratada em formato JSON, e os dados relevantes foram extra√≠dos e convertidos para um DataFrame com o aux√≠lio da biblioteca Pandas.
---

## 2. üìÑ Gera√ß√£o do Arquivo CSV
Ap√≥s o tratamento dos dados, o DataFrame foi exportado para um arquivo .csv:

```
books_df = pd.DataFrame(books_list)
books_df.to_csv("google_books.csv", index=False)
3. ‚òÅÔ∏è Upload para o Google Cloud Storage
```
O arquivo CSV gerado foi enviado para um bucket no Google Cloud Storage com o seguinte c√≥digo:

```
from google.cloud import storage

storage_client = storage.Client()
bucket = storage_client.bucket(bucket_name)
blob = bucket.blob(destination_blob_name)
blob.upload_from_filename(source_file_name)
```
---

## 4. üß† Integra√ß√£o com BigQuery
Com o arquivo j√° armazenado no bucket, realizamos a importa√ß√£o dos dados para uma tabela no BigQuery. A tabela foi criada com esquema autom√°tico, permitindo consultas SQL para an√°lise dos dados.

---
# Resultados Esperados
Visualiza√ß√£o dos principais livros sobre Python dispon√≠veis na Google Books API.

Armazenamento seguro e escal√°vel dos dados em nuvem.

An√°lises estat√≠sticas e explorat√≥rias via SQL no BigQuery.

Pipeline funcional e replic√°vel para outros temas ou fontes de dados.

---
# Como Executar
Clone este reposit√≥rio.

Configure suas credenciais do Google Cloud no Colab.

Execute o notebook passo a passo.

Verifique os dados no BigQuery e explore com SQL.
